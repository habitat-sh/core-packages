# Habitat Package: RabbitMQ

The Habitat Maintainers <humans@habitat.sh>

## Description

Habitat package for the [RabbitMQ open source message broker](https://www.rabbitmq.com/).

## Cluster Support

This package supports clustering multiple RabbitMQ systems together using the Habitat supervisor ring.

All systems in the cluster must know each other by hostname. This can be done in DNS or `/etc/hosts`.

On the first "seed" system, start up a permanent peer in a leader topology.

```
hab start core/rabbitmq -t leader -I
```

Create configuration that enables the cluster, and set the Erlang cookie.

```
[erlang]
cookie = "66a11b4e60d6f25468bd1b283dd9caa5b13c1117a17b0b1cba403fb7d88db769281e"

[rabbitmq.cluster]
enabled = true
```

Then, apply the configuration so it is available in the ring.


```
devbox$ hab config apply rabbitmq.default 1 rabbitmq-cluster.toml --peer 172.17.0.2
```

Start the Habitat supervisor on the other systems in the cluster using the permanent peer.

```
hab start core/rabbitmq -t leader --peer 172.17.0.2
```

Once RabbitMQ updates and restarts, verify that the nodes are members of the cluster with `rabbitmqctl`. The `$HOME` environment must be set so that the `rabbitmqctl` command uses the cookie generated by Habitat.

```
root@12a119db54f1# HOME=/hab/svc/rabbitmq/var rabbitmqctl cluster_status
Cluster status of node rabbit@12a119db54f1
[{nodes,[{disc,[rabbit@12a119db54f1,rabbit@184cb5e832e8,
                rabbit@b2f3ce883c3d]}]},
 {running_nodes,[rabbit@184cb5e832e8,rabbit@b2f3ce883c3d,rabbit@12a119db54f1]},
 {cluster_name,<<"rabbit@12a119db54f1">>},
 {partitions,[]},
 {alarms,[{rabbit@184cb5e832e8,[]},
          {rabbit@b2f3ce883c3d,[]},
          {rabbit@12a119db54f1,[]}]}]
```

## Docker Compose

The rabbitmq core plan includes a `docker-compose.yml` that can be used to set up a sample cluster uing the method above, for testing purposes. In a local clone of the `core-plans` repository:

```
% cd rabbitmq
% docker-compose up -d
% docker-compose exec rabbitmq1 bash
```

Once inside the container:

```
/ # echo -e "[rabbitmq.cluster]\nenabled = true\n[erlang]\ncookie='Wiffle-ball-bat'" | hab config apply --peer localhost rabbitmq.default 1
```

It will take a few moments for the services to all apply the configuration and restart the application. Verify using `rabbitmqctl`. You'll need to binlink the `erl` binary first:

```
/ # hab pkg binlink core/erlang19
/ # HOME=/hab/svc/rabbitmq/var rabbitmqctl cluster_status
```

If everything is operational, you'll see output like this:

```
Cluster status of node rabbit@42ebfdfbc4a9
[{nodes,[{disc,[rabbit@42ebfdfbc4a9,rabbit@f17ee1a51415,
                rabbit@fe2d32319945]}]},
 {running_nodes,[rabbit@f17ee1a51415,rabbit@fe2d32319945,rabbit@42ebfdfbc4a9]},
 {cluster_name,<<"rabbit@42ebfdfbc4a9">>},
 {partitions,[]},
 {alarms,[{rabbit@f17ee1a51415,[]},
          {rabbit@fe2d32319945,[]},
          {rabbit@42ebfdfbc4a9,[]}]}]
```

Note the `running_nodes`, which should correspond to the running containers from `docker-compose ps -a` or `docker ps -a | grep 'rabbitmq[123]`.

```
% docker ps -a | grep 'rabbitmq[123]'
f17ee1a51415   core/rabbitmq   "/init.sh start co..."   6 minutes ago   Up 6 minutes  5672/tcp, 9631/tcp   rabbitmq_rabbitmq3_1
fe2d32319945   core/rabbitmq   "/init.sh start co..."   6 minutes ago   Up 6 minutes  5672/tcp, 9631/tcp   rabbitmq_rabbitmq2_1
42ebfdfbc4a9   core/rabbitmq   "/init.sh start co..."   6 minutes ago   Up 6 minutes  5672/tcp, 9631/tcp   rabbitmq_rabbitmq1_1
```

### Erlang Cookie

Note that the Erlang cookie is a configuration file that will always be generated using the value of `erlang.cookie`, which defaults to `false`. This only gets copied over to the target location (`/hab/svc/rabbitmq/var/.erlang.cookie`) if a value is set. RabbitMQ will generate its own random string for the cookie if the configuration value is not set by Habitat. The cookie *must* match on all RabbitMQ cluster nodes, and any time the `rabbitmqctl` command is used to inspect the running service.
